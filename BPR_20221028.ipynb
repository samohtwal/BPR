{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOIN8t2qWALMKYterQxq6lK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samohtwal/BPR/blob/20221027/BPR_20221028.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FKoQOpY8f-BH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import copy\n",
        "from itertools import islice\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "global raw_data_user_column_name\n",
        "global raw_data_item_column_name\n",
        "\n",
        "global raw_data_group_by_user_id_dictionary_key\n",
        "global raw_data_group_by_item_id_dictionary_key\n",
        "\n",
        "global user_latent_factor_matrix_dictionary_key\n",
        "global item_latent_factor_matrix_dictionary_key\n",
        "\n",
        "global user_latent_factor_matrix_file_name\n",
        "global item_latent_factor_matrix_file_name\n",
        "\n",
        "raw_data_user_column_name = 'user_id'\n",
        "raw_data_item_column_name = 'item_id'\n",
        "\n",
        "raw_data_group_by_user_id_dictionary_key = 'raw_data_group_by_user_id'\n",
        "raw_data_group_by_item_id_dictionary_key = 'raw_data_group_by_item_id'\n",
        "\n",
        "user_latent_factor_matrix_dictionary_key = 'user_latent_factor_matrix'\n",
        "item_latent_factor_matrix_dictionary_key = 'item_latent_factor_matrix'\n",
        "\n",
        "user_latent_factor_matrix_file_name = 'user_latent_factor_matrix'\n",
        "item_latent_factor_matrix_file_name = 'item_latent_factor_matrix'"
      ],
      "metadata": {
        "id": "17RUQMyLgI_z"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataHelper:\n",
        "\n",
        "    def load_raw_data_dictionary(self, raw_data_url):\n",
        "\n",
        "        column_names = [raw_data_user_column_name, raw_data_item_column_name]\n",
        "        raw_data = pd.read_csv(raw_data_url, names = column_names, header=0)\n",
        "\n",
        "        raw_data_group_by_user_id = raw_data.groupby(raw_data_user_column_name)[raw_data_item_column_name].apply(list).reset_index(name=raw_data_item_column_name).sort_values(by=[raw_data_user_column_name])\n",
        "        raw_data_group_by_item_id = raw_data.groupby(raw_data_item_column_name)[raw_data_user_column_name].apply(list).reset_index(name=raw_data_user_column_name).sort_values(by=[raw_data_item_column_name])\n",
        "\n",
        "        raw_data_dictionary = {\n",
        "            raw_data_group_by_user_id_dictionary_key: raw_data_group_by_user_id, \n",
        "            raw_data_group_by_item_id_dictionary_key: raw_data_group_by_item_id\n",
        "        }\n",
        "\n",
        "        return raw_data_dictionary\n",
        "\n",
        "    def save_latent_factor_matrix_dictionary(self, latent_factor_matrix_dictionary):\n",
        "\n",
        "        user_latent_factor_matrix = latent_factor_matrix_dictionary.get(user_latent_factor_matrix_dictionary_key)\n",
        "        item_latent_factor_matrix = latent_factor_matrix_dictionary.get(item_latent_factor_matrix_dictionary_key)\n",
        "        \n",
        "        pd.DataFrame(user_latent_factor_matrix).to_csv(user_latent_factor_matrix_file_name)\n",
        "        pd.DataFrame(item_latent_factor_matrix).to_csv(item_latent_factor_matrix_file_name)\n",
        "\n",
        "        return None\n",
        "\n",
        "    def load_latent_factor_matrix_dictionary(self):\n",
        "\n",
        "        user_latent_factor_matrix = pd.read_csv(user_latent_factor_matrix_file_name)\n",
        "        item_latent_factor_matrix = pd.read_csv(item_latent_factor_matrix_file_name)\n",
        "\n",
        "        latent_factor_matrix_dictionary = {\n",
        "            user_latent_factor_matrix_dictionary_key: user_latent_factor_matrix, \n",
        "            item_latent_factor_matrix_dictionary_key: item_latent_factor_matrix\n",
        "        }\n",
        "\n",
        "        return latent_factor_matrix_dictionary"
      ],
      "metadata": {
        "id": "wjgEH2jmgLv1"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BayseianPersonalizedRanking:\n",
        "\n",
        "    def __init__(self, random_seed = 1234, n_latent_factor = 15, n_batch = 10, learning_rate = 0.01, regularization_constant = 0.01):\n",
        "        self.random_seed = random_seed\n",
        "        self.n_latent_factor = n_latent_factor\n",
        "        self.n_batch = n_batch\n",
        "        self.learning_rate = learning_rate\n",
        "        self.regularization_constant = regularization_constant\n",
        "\n",
        "    def fit(self, raw_data_group_by_user_id, raw_data_group_by_item_id):\n",
        "\n",
        "        n_user = len(raw_data_group_by_user_id[raw_data_user_column_name])\n",
        "        n_item = len(raw_data_group_by_item_id[raw_data_item_column_name])\n",
        "\n",
        "        rstate = np.random.RandomState(self.random_seed)\n",
        "\n",
        "        user_latent_factor_matrix = rstate.normal(size = (n_user, self.n_latent_factor))\n",
        "        item_latent_factor_matrix = rstate.normal(size = (n_item, self.n_latent_factor))\n",
        "\n",
        "        user_item_rating_matrix = self._create_user_item_rating_matrix(raw_data_group_by_user_id, raw_data_group_by_item_id)\n",
        "\n",
        "        user_latent_factor_matrixes = []\n",
        "        item_latent_factor_matrixes = []\n",
        "        sum_of_square_errors = []\n",
        "\n",
        "        is_converage = True\n",
        "        counter = 1\n",
        "        while is_converge:\n",
        "            \n",
        "            sample_latent_factor_matrix_row_indexes = self._create_sample_latent_factor_matrix_row_indexes(raw_data_group_by_user_id, raw_data_group_by_item_id)\n",
        "            sample_user_id_indexes, sample_positive_item_id_indexes, sample_negative_item_id_indexes = sample_latent_factor_matrix_row_indexes\n",
        "            user_latent_factor_matrix, item_latent_factor_matrix = self._update_sample_latent_factor_matrix_rows(user_latent_factor_matrix, item_latent_factor_matrix, sample_user_id_indexes, sample_positive_item_id_indexes, sample_negative_item_id_indexes)\n",
        "            sum_of_square_error = np.sum((user_item_rating_matrix - self._predict(user_latent_factor_matrix, item_latent_factor_matrix))**2)\n",
        "            \n",
        "            user_latent_factor_matrixes.append(user_latent_factor_matrix)\n",
        "            item_latent_factor_matrixes.append(item_latent_factor_matrix)\n",
        "            sum_of_square_errors.append(sum_of_square_error)\n",
        "            \n",
        "            print('debug - iteration:', counter, end='\\n')\n",
        "            print('debug - sum_of_square_error:', sum_of_square_error, end='\\n')\n",
        "            \n",
        "            n_sum_of_square_error = len(sum_of_square_errors)\n",
        "            if (sum_of_square_errors[n_sum_of_square_error-1] > sum_of_square_errors[n_sum_of_square_error-2]):\n",
        "                is_converge = False\n",
        "\n",
        "            counter = counter + 1\n",
        "\n",
        "        latent_factor_matrix_dictionary = {\n",
        "            user_latent_factor_matrix_dictionary_key: user_latent_factor_matrix, \n",
        "            item_latent_factor_matrix_dictionary_key: item_latent_factor_matrix\n",
        "        }\n",
        "\n",
        "        return latent_factor_matrix_dictionary\n",
        "\n",
        "    def _create_user_item_rating_matrix(raw_data_group_by_user_id, raw_data_group_by_item_id):\n",
        "\n",
        "        n_user = len(raw_data_group_by_user_id[raw_data_user_column_name])\n",
        "        n_item = len(raw_data_group_by_item_id[raw_data_item_column_name])\n",
        "\n",
        "        user_ids = raw_data_group_by_user_id[raw_data_user_column_name].tolist()\n",
        "        item_ids = raw_data_group_by_item_id[raw_data_item_column_name].tolist()\n",
        "\n",
        "        user_item_rating_matrix = np.zeros((n_user, n_item), dtype = np.int64)\n",
        "        for user_id_index, user_id in enumerate(user_ids):\n",
        "            item_id_indexes = np.where(np.isin(raw_data_group_by_user_id.iloc[user_id_index][raw_data_item_column_name],item_ids))[0]\n",
        "            for item_id_index in item_id_indexes:\n",
        "                user_item_rating_matrix[user_id_index, item_id_index] = 1\n",
        "\n",
        "        return user_item_rating_matrix\n",
        "\n",
        "    def _create_sample_latent_factor_matrix_row_indexes(self, raw_data_group_by_user_id, raw_data_group_by_item_id):\n",
        "\n",
        "        n_user = len(raw_data_group_by_user_id[raw_data_user_column_name])\n",
        "        n_item = len(raw_data_group_by_item_id[raw_data_item_column_name])\n",
        "\n",
        "        item_ids = raw_data_group_by_item_id[raw_data_item_column_name].tolist()\n",
        "\n",
        "        sample_user_id_indexes = np.random.choice(n_user, size = self.n_batch, replace = False)\n",
        "        sample_positive_item_id_indexes = np.zeros(self.n_batch, dtype = np.int64)\n",
        "        sample_negative_item_id_indexes = np.zeros(self.n_batch, dtype = np.int64)\n",
        "\n",
        "        for index, sampled_user_id_index in enumerate(sample_user_id_indexes):\n",
        "            possible_positive_item_ids = raw_data_group_by_user_id.iloc[sampled_user_id_index][raw_data_item_column_name]\n",
        "            possible_negative_item_ids = list(set(item_ids).difference(possible_positive_item_ids))\n",
        "            sample_positive_item_id = np.random.choice(possible_positive_item_ids)\n",
        "            sample_negative_item_id = np.random.choice(possible_negative_item_ids)\n",
        "            sample_positive_item_id_indexes[index] = item_ids.index(sample_positive_item_id)\n",
        "            sample_negative_item_id_indexes[index] = item_ids.index(sample_negative_item_id)\n",
        "\n",
        "        return sample_user_id_indexes, sample_positive_item_id_indexes, sample_negative_item_id_indexes\n",
        "\n",
        "    def _update_sample_latent_factor_matrix_rows(self, user_latent_factor_matrix, item_latent_factor_matrix, sample_user_id_indexes, sample_positive_item_id_indexes, sample_negative_item_id_indexes):\n",
        "\n",
        "        sample_user_latent_factor_matrix_tuple = user_latent_factor_matrix[sample_user_id_indexes]\n",
        "        sample_item_latent_factor_matrix_positive_item_tuple = item_latent_factor_matrix[sample_positive_item_id_indexes]\n",
        "        sample_item_latent_factor_matrix_negative_item_tuple = item_latent_factor_matrix[sample_negative_item_id_indexes]\n",
        "\n",
        "        r_uij = np.sum(sample_user_latent_factor_matrix_tuple * (sample_item_latent_factor_matrix_positive_item_tuple - sample_item_latent_factor_matrix_negative_item_tuple), axis = 1)\n",
        "        sigmoid = np.exp(-r_uij) / (1.0 + np.exp(-r_uij))\n",
        "        sigmoid_tiled = np.tile(sigmoid, (self.n_latent_factor, 1)).T\n",
        "\n",
        "        gradient_user = sigmoid_tiled * (sample_item_latent_factor_matrix_negative_item_tuple - sample_item_latent_factor_matrix_positive_item_tuple) + self.regularization_constant * sample_user_latent_factor_matrix_tuple\n",
        "        gradient_positive_item = sigmoid_tiled * -sample_user_latent_factor_matrix_tuple + self.regularization_constant * sample_item_latent_factor_matrix_positive_item_tuple\n",
        "        gradient_negative_item = sigmoid_tiled * sample_user_latent_factor_matrix_tuple + self.regularization_constant * sample_item_latent_factor_matrix_negative_item_tuple\n",
        "\n",
        "        user_latent_factor_matrix[sample_user_id_indexes] -= self.learning_rate * gradient_user\n",
        "        item_latent_factor_matrix[sample_positive_item_id_indexes] -= self.learning_rate * gradient_positive_item\n",
        "        item_latent_factor_matrix[sample_negative_item_id_indexes] -= self.learning_rate * gradient_negative_item\n",
        "\n",
        "        return user_latent_factor_matrix, item_latent_factor_matrix\n",
        "\n",
        "    def recommend_user(self, user_latent_factor_matrix, item_latent_factor_matrix, raw_data_group_by_user_id, raw_data_group_by_item_id, user_id, n_best_recommendation):\n",
        "\n",
        "        user_ids = raw_data_group_by_user_id[raw_data_user_column_name].tolist()\n",
        "        item_ids = raw_data_group_by_item_id[raw_data_item_column_name].tolist()\n",
        "\n",
        "        user_index = user_ids.index(user_id)\n",
        "\n",
        "        scores = self._predict_user(user_latent_factor_matrix, item_latent_factor_matrix, user_index)\n",
        "        user_latent_factor_dictionary = {item_ids[i]: scores[i] for i in range(len(item_ids))}\n",
        "\n",
        "        positive_item_ids = raw_data_group_by_user_id.iloc[user_index][raw_data_item_column_name]\n",
        "\n",
        "        user_latent_factor_dictionary = {key: user_latent_factor_dictionary[key] for key in item_ids if key not in positive_item_ids}\n",
        "        user_latent_factor_dictionary = dict(sorted(user_latent_factor_dictionary.items(), key=lambda item: item[1], reverse=True))\n",
        "        best_recommendition_items = dict(islice(user_latent_factor_dictionary.items(), n_best_recommendation))\n",
        "\n",
        "        return list(best_recommendition_items.keys())[0:n_best_recommendation]\n",
        "\n",
        "    def _predict(user_latent_factor_matrix, item_latent_factor_matrix):\n",
        "        return user_latent_factor_matrix.dot(item_latent_factor_matrix.T)\n",
        "\n",
        "    def _predict_user(user_latent_factor_matrix, item_latent_factor_matrix, user_index):\n",
        "        return user_latent_factor_matrix[user_index].dot(item_latent_factor_matrix.T)"
      ],
      "metadata": {
        "id": "R_41q8ucjFoA"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_raw_data_url = 'https://raw.githubusercontent.com/samohtwal/BPR/main/data/vali-20221026.csv'\n",
        "data_helper = DataHelper()\n",
        "raw_data_dictionary = data_helper.load_raw_data_dictionary(test_raw_data_url)\n",
        "\n",
        "print('debug - raw_data_dictionary[raw_data_group_by_user_id_dictionary_key]:', end='\\n')\n",
        "print(raw_data_dictionary[raw_data_group_by_user_id_dictionary_key], end='\\n')\n",
        "print('', end='\\n')\n",
        "\n",
        "print('debug - raw_data_dictionary[raw_data_group_by_item_id_dictionary_key]:', end='\\n')\n",
        "print(raw_data_dictionary[raw_data_group_by_item_id_dictionary_key], end='\\n')\n",
        "print('', end='\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7X55kIdA17i-",
        "outputId": "21481caa-60a9-4688-f7a5-9b333c178ce1"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "debug - raw_data_dictionary[raw_data_group_by_user_id_dictionary_key]:\n",
            "      user_id                                            item_id\n",
            "0           0                             [128, 319, 2352, 2688]\n",
            "1           1  [109, 985, 1201, 1294, 1324, 1345, 1427, 1664,...\n",
            "2           2                                             [2633]\n",
            "3           3  [142, 150, 237, 252, 320, 333, 461, 477, 479, ...\n",
            "4           4                                             [1779]\n",
            "...       ...                                                ...\n",
            "3859     3919                                       [1883, 2002]\n",
            "3860     3920                                 [1805, 1845, 1907]\n",
            "3861     3921                                       [1884, 2135]\n",
            "3862     3922                                 [1803, 1885, 1926]\n",
            "3863     3923               [1983, 2201, 2214, 2314, 2413, 2489]\n",
            "\n",
            "[3864 rows x 2 columns]\n",
            "\n",
            "debug - raw_data_dictionary[raw_data_group_by_item_id_dictionary_key]:\n",
            "      item_id                                            user_id\n",
            "0           0                                          [6, 7, 9]\n",
            "1           1                                               [15]\n",
            "2           2                                           [28, 29]\n",
            "3           3                                       [37, 39, 44]\n",
            "4           4                                               [49]\n",
            "...       ...                                                ...\n",
            "2992     3053  [1262, 1024, 856, 3441, 3681, 1403, 2236, 922,...\n",
            "2993     3054           [2793, 3246, 782, 754, 2122, 1737, 2148]\n",
            "2994     3055                            [3655, 1827, 270, 3653]\n",
            "2995     3056                     [2961, 2548, 3755, 2019, 3546]\n",
            "2996     3057                     [1366, 1689, 1858, 2024, 2148]\n",
            "\n",
            "[2997 rows x 2 columns]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v0jDnnAc3-kx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}