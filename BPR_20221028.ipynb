{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPR+p7PwyeaflQCNN59dcqx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samohtwal/BPR/blob/20221027/BPR_20221028.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FKoQOpY8f-BH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import copy\n",
        "from itertools import islice\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "global raw_data_user_column_name\n",
        "global raw_data_item_column_name\n",
        "\n",
        "global raw_data_group_by_user_id_dictionary_key\n",
        "global raw_data_group_by_item_id_dictionary_key\n",
        "\n",
        "global user_latent_factor_matrix_dictionary_key\n",
        "global item_latent_factor_matrix_dictionary_key\n",
        "\n",
        "global user_latent_factor_matrix_file_name\n",
        "global item_latent_factor_matrix_file_name\n",
        "\n",
        "raw_data_user_column_name = 'user_id'\n",
        "raw_data_item_column_name = 'item_id'\n",
        "\n",
        "raw_data_group_by_user_id_dictionary_key = 'raw_data_group_by_user_id'\n",
        "raw_data_group_by_item_id_dictionary_key = 'raw_data_group_by_item_id'\n",
        "\n",
        "user_latent_factor_matrix_dictionary_key = 'user_latent_factor_matrix'\n",
        "item_latent_factor_matrix_dictionary_key = 'item_latent_factor_matrix'\n",
        "\n",
        "user_latent_factor_matrix_file_name = 'user_latent_factor_matrix'\n",
        "item_latent_factor_matrix_file_name = 'item_latent_factor_matrix'"
      ],
      "metadata": {
        "id": "17RUQMyLgI_z"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataHelper:\n",
        "\n",
        "    def load_raw_data_dictionary(raw_data_url):\n",
        "\n",
        "        column_names = [raw_data_user_column_name, raw_data_item_column_name]\n",
        "        raw_data = pd.read_csv(raw_data_url, names = column_names, header=0)\n",
        "\n",
        "        raw_data_group_by_user_id = raw_data.groupby(raw_data_user_column_name)[raw_data_item_column_name].apply(list).reset_index(name=raw_data_item_column_name).sort_values(by=[raw_data_user_column_name])\n",
        "        raw_data_group_by_item_id = raw_data.groupby(raw_data_item_column_name)[raw_data_user_column_name].apply(list).reset_index(name=raw_data_user_column_name).sort_values(by=[raw_data_item_column_name])\n",
        "\n",
        "        raw_data_dictionary = {\n",
        "            raw_data_group_by_user_id_dictionary_key: raw_data_group_by_user_id, \n",
        "            raw_data_group_by_item_id_dictionary_key: raw_data_group_by_item_id\n",
        "        }\n",
        "\n",
        "        return raw_data_dictionary\n",
        "\n",
        "    def save_latent_factor_matrix_dictionary(self, latent_factor_matrix_dictionary):\n",
        "\n",
        "        user_latent_factor_matrix = latent_factor_matrix_dictionary.get(user_latent_factor_matrix_dictionary_key)\n",
        "        item_latent_factor_matrix = latent_factor_matrix_dictionary.get(item_latent_factor_matrix_dictionary_key)\n",
        "        \n",
        "        pd.DataFrame(user_latent_factor_matrix).to_csv(user_latent_factor_matrix_file_name)\n",
        "        pd.DataFrame(item_latent_factor_matrix).to_csv(item_latent_factor_matrix_file_name)\n",
        "\n",
        "        return None\n",
        "\n",
        "    def load_latent_factor_matrix_dictionary(self):\n",
        "\n",
        "        user_latent_factor_matrix = pd.read_csv(user_latent_factor_matrix_file_name)\n",
        "        item_latent_factor_matrix = pd.read_csv(item_latent_factor_matrix_file_name)\n",
        "\n",
        "        latent_factor_matrix_dictionary = {\n",
        "            user_latent_factor_matrix_dictionary_key: user_latent_factor_matrix, \n",
        "            item_latent_factor_matrix_dictionary_key: item_latent_factor_matrix\n",
        "        }\n",
        "\n",
        "        return latent_factor_matrix_dictionary"
      ],
      "metadata": {
        "id": "wjgEH2jmgLv1"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BayseianPersonalizedRanking:\n",
        "\n",
        "    def __init__(self, random_seed = 1234, n_latent_factor = 15, n_batch = 10, learning_rate = 0.01, regularization_constant = 0.01):\n",
        "        self.random_seed = random_seed\n",
        "        self.n_latent_factor = n_latent_factor\n",
        "        self.n_batch = n_batch\n",
        "        self.learning_rate = learning_rate\n",
        "        self.regularization_constant = regularization_constant\n",
        "\n",
        "    def fit(self, raw_data_group_by_user_id, raw_data_group_by_item_id):\n",
        "\n",
        "        n_user = len(raw_data_group_by_user_id[raw_data_user_column_name])\n",
        "        n_item = len(raw_data_group_by_item_id[raw_data_item_column_name])\n",
        "\n",
        "        rstate = np.random.RandomState(self.random_seed)\n",
        "\n",
        "        user_latent_factor_matrix = rstate.normal(size = (n_user, self.n_latent_factor))\n",
        "        item_latent_factor_matrix = rstate.normal(size = (n_item, self.n_latent_factor))\n",
        "\n",
        "        user_item_rating_matrix = self._create_user_item_rating_matrix(raw_data_group_by_user_id, raw_data_group_by_item_id)\n",
        "\n",
        "        user_latent_factor_matrixes = []\n",
        "        item_latent_factor_matrixes = []\n",
        "        sum_of_square_errors = []\n",
        "\n",
        "        is_converage = True\n",
        "        counter = 1\n",
        "        while is_converge:\n",
        "            \n",
        "            sample_latent_factor_matrix_row_indexes = self._create_sample_latent_factor_matrix_row_indexes(raw_data_group_by_user_id, raw_data_group_by_item_id)\n",
        "            sample_user_id_indexes, sample_positive_item_id_indexes, sample_negative_item_id_indexes = sample_latent_factor_matrix_row_indexes\n",
        "            user_latent_factor_matrix, item_latent_factor_matrix = self._update_sample_latent_factor_matrix_rows(user_latent_factor_matrix, item_latent_factor_matrix, sample_user_id_indexes, sample_positive_item_id_indexes, sample_negative_item_id_indexes)\n",
        "            sum_of_square_error = np.sum((user_item_rating_matrix - self._predict(user_latent_factor_matrix, item_latent_factor_matrix))**2)\n",
        "            \n",
        "            user_latent_factor_matrixes.append(user_latent_factor_matrix)\n",
        "            item_latent_factor_matrixes.append(item_latent_factor_matrix)\n",
        "            sum_of_square_errors.append(sum_of_square_error)\n",
        "            \n",
        "            print('debug - iteration:', counter, end='\\n')\n",
        "            print('debug - sum_of_square_error:', sum_of_square_error, end='\\n')\n",
        "            \n",
        "            n_sum_of_square_error = len(sum_of_square_errors)\n",
        "            if (sum_of_square_errors[n_sum_of_square_error-1] > sum_of_square_errors[n_sum_of_square_error-2]):\n",
        "                is_converge = False\n",
        "\n",
        "            counter = counter + 1\n",
        "\n",
        "        latent_factor_matrix_dictionary = {\n",
        "            user_latent_factor_matrix_dictionary_key: user_latent_factor_matrix, \n",
        "            item_latent_factor_matrix_dictionary_key: item_latent_factor_matrix\n",
        "        }\n",
        "\n",
        "        return latent_factor_matrix_dictionary\n",
        "\n",
        "    def _create_user_item_rating_matrix(raw_data_group_by_user_id, raw_data_group_by_item_id):\n",
        "\n",
        "        n_user = len(raw_data_group_by_user_id[raw_data_user_column_name])\n",
        "        n_item = len(raw_data_group_by_item_id[raw_data_item_column_name])\n",
        "\n",
        "        user_ids = raw_data_group_by_user_id[raw_data_user_column_name].tolist()\n",
        "        item_ids = raw_data_group_by_item_id[raw_data_item_column_name].tolist()\n",
        "\n",
        "        user_item_rating_matrix = np.zeros((n_user, n_item), dtype = np.int64)\n",
        "        for user_id_index, user_id in enumerate(user_ids):\n",
        "            item_id_indexes = np.where(np.isin(raw_data_group_by_user_id.iloc[user_id_index][raw_data_item_column_name],item_ids))[0]\n",
        "            for item_id_index in item_id_indexes:\n",
        "                user_item_rating_matrix[user_id_index, item_id_index] = 1\n",
        "\n",
        "        return user_item_rating_matrix\n",
        "\n",
        "    def _create_sample_latent_factor_matrix_row_indexes(self, raw_data_group_by_user_id, raw_data_group_by_item_id):\n",
        "\n",
        "        n_user = len(raw_data_group_by_user_id[raw_data_user_column_name])\n",
        "        n_item = len(raw_data_group_by_item_id[raw_data_item_column_name])\n",
        "\n",
        "        item_ids = raw_data_group_by_item_id[raw_data_item_column_name].tolist()\n",
        "\n",
        "        sample_user_id_indexes = np.random.choice(n_user, size = self.n_batch, replace = False)\n",
        "        sample_positive_item_id_indexes = np.zeros(self.n_batch, dtype = np.int64)\n",
        "        sample_negative_item_id_indexes = np.zeros(self.n_batch, dtype = np.int64)\n",
        "\n",
        "        for index, sampled_user_id_index in enumerate(sample_user_id_indexes):\n",
        "            possible_positive_item_ids = raw_data_group_by_user_id.iloc[sampled_user_id_index][raw_data_item_column_name]\n",
        "            possible_negative_item_ids = list(set(item_ids).difference(possible_positive_item_ids))\n",
        "            sample_positive_item_id = np.random.choice(possible_positive_item_ids)\n",
        "            sample_negative_item_id = np.random.choice(possible_negative_item_ids)\n",
        "            sample_positive_item_id_indexes[index] = item_ids.index(sample_positive_item_id)\n",
        "            sample_negative_item_id_indexes[index] = item_ids.index(sample_negative_item_id)\n",
        "\n",
        "        return sample_user_id_indexes, sample_positive_item_id_indexes, sample_negative_item_id_indexes\n",
        "\n",
        "    def _update_sample_latent_factor_matrix_rows(self, user_latent_factor_matrix, item_latent_factor_matrix, sample_user_id_indexes, sample_positive_item_id_indexes, sample_negative_item_id_indexes):\n",
        "\n",
        "        sample_user_latent_factor_matrix_tuple = user_latent_factor_matrix[sample_user_id_indexes]\n",
        "        sample_item_latent_factor_matrix_positive_item_tuple = item_latent_factor_matrix[sample_positive_item_id_indexes]\n",
        "        sample_item_latent_factor_matrix_negative_item_tuple = item_latent_factor_matrix[sample_negative_item_id_indexes]\n",
        "\n",
        "        r_uij = np.sum(sample_user_latent_factor_matrix_tuple * (sample_item_latent_factor_matrix_positive_item_tuple - sample_item_latent_factor_matrix_negative_item_tuple), axis = 1)\n",
        "        sigmoid = np.exp(-r_uij) / (1.0 + np.exp(-r_uij))\n",
        "        sigmoid_tiled = np.tile(sigmoid, (self.n_latent_factor, 1)).T\n",
        "\n",
        "        gradient_user = sigmoid_tiled * (sample_item_latent_factor_matrix_negative_item_tuple - sample_item_latent_factor_matrix_positive_item_tuple) + self.regularization_constant * sample_user_latent_factor_matrix_tuple\n",
        "        gradient_positive_item = sigmoid_tiled * -sample_user_latent_factor_matrix_tuple + self.regularization_constant * sample_item_latent_factor_matrix_positive_item_tuple\n",
        "        gradient_negative_item = sigmoid_tiled * sample_user_latent_factor_matrix_tuple + self.regularization_constant * sample_item_latent_factor_matrix_negative_item_tuple\n",
        "\n",
        "        user_latent_factor_matrix[sample_user_id_indexes] -= self.learning_rate * gradient_user\n",
        "        item_latent_factor_matrix[sample_positive_item_id_indexes] -= self.learning_rate * gradient_positive_item\n",
        "        item_latent_factor_matrix[sample_negative_item_id_indexes] -= self.learning_rate * gradient_negative_item\n",
        "\n",
        "        return user_latent_factor_matrix, item_latent_factor_matrix\n",
        "\n",
        "    def recommend_user(self, user_latent_factor_matrix, item_latent_factor_matrix, raw_data_group_by_user_id, raw_data_group_by_item_id, user_id, n_best_recommendation):\n",
        "\n",
        "        user_ids = raw_data_group_by_user_id[raw_data_user_column_name].tolist()\n",
        "        item_ids = raw_data_group_by_item_id[raw_data_item_column_name].tolist()\n",
        "\n",
        "        user_index = user_ids.index(user_id)\n",
        "\n",
        "        scores = self._predict_user(user_latent_factor_matrix, item_latent_factor_matrix, user_index)\n",
        "        user_latent_factor_dictionary = {item_ids[i]: scores[i] for i in range(len(item_ids))}\n",
        "\n",
        "        positive_item_ids = raw_data_group_by_user_id.iloc[user_index][raw_data_item_column_name]\n",
        "\n",
        "        user_latent_factor_dictionary = {key: user_latent_factor_dictionary[key] for key in item_ids if key not in positive_item_ids}\n",
        "        user_latent_factor_dictionary = dict(sorted(user_latent_factor_dictionary.items(), key=lambda item: item[1], reverse=True))\n",
        "        best_recommendition_items = dict(islice(user_latent_factor_dictionary.items(), n_best_recommendation))\n",
        "\n",
        "        return list(best_recommendition_items.keys())[0:n_best_recommendation]\n",
        "\n",
        "    def _predict(user_latent_factor_matrix, item_latent_factor_matrix):\n",
        "        return user_latent_factor_matrix.dot(item_latent_factor_matrix.T)\n",
        "\n",
        "    def _predict_user(user_latent_factor_matrix, item_latent_factor_matrix, user_index):\n",
        "        return user_latent_factor_matrix[user_index].dot(item_latent_factor_matrix.T)"
      ],
      "metadata": {
        "id": "R_41q8ucjFoA"
      },
      "execution_count": 36,
      "outputs": []
    }
  ]
}